% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/benchmarking.R
\name{run_evals}
\alias{run_evals}
\title{run_evals: Main function to benchmark FDR methods on given simulations.}
\usage{
run_evals(sim_funs, fdr_methods, nreps, alphas, ...)
}
\arguments{
\item{sim_funs}{List of simulation settings}

\item{fdr_methods}{List of FDR controlling methods to be benchmarked}

\item{nreps}{Integer, number of Monte Carlo replicates for the simulations}

\item{alphas}{Numeric, vector of nominal significance levels 
at which to apply FDR controlling methods}

\item{...}{Additional arguments passed to sim_fun_eval}
}
\value{
data.frame which summarizes results of numerical experiment
}
\description{
run_evals: Main function to benchmark FDR methods on given simulations.
}

